{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import the necessary libraries"
      ],
      "metadata": {
        "id": "re5MiwLfaOER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vk7mBYhgZXSZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the data"
      ],
      "metadata": {
        "id": "60pTl8OF81SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('creditcard.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Tg9u03Ev75u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Total null value in dataset"
      ],
      "metadata": {
        "id": "K_xHV9Fj-lcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum().sum())\n",
        "# No null values\n",
        "df.dropna(inplace = True)"
      ],
      "metadata": {
        "id": "8YXlxH7R-jHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "M2q1TRw79_by"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T.head()"
      ],
      "metadata": {
        "id": "uGIrRxmg-N9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate the number of genuine and fraud transactions"
      ],
      "metadata": {
        "id": "6UQZL1AjLE75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genuine_transactions = df[df['Class'] == 0]  # assuming 'Class' indicates fraud (1) or genuine (0)\n",
        "fraud_transactions = df[df['Class'] == 1]\n",
        "\n",
        "num_genuine = len(genuine_transactions)\n",
        "num_fraud = len(fraud_transactions)\n",
        "\n",
        "fraud_percentage = (num_fraud / len(df)) * 100\n",
        "print(f\"Number of genuine transactions: {num_genuine}\")\n",
        "print(f\"Number of fraud transactions: {num_fraud}\")\n",
        "print(f\"Percentage of fraud transactions: {fraud_percentage}%\")"
      ],
      "metadata": {
        "id": "oeX0nwzr-9LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation map\n"
      ],
      "metadata": {
        "id": "6VwvOyj3MwJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "numData = df.select_dtypes(include=[int,float])\n",
        "corrMat = numData.corr()\n",
        "sns.heatmap(corrMat,cmap='Blues')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tDTmbkWcSLA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df['NormalizedAmount'] = scaler.fit_transform(df[['Amount']])"
      ],
      "metadata": {
        "id": "m_UnLdBtMqrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the dataset into training and testing sets"
      ],
      "metadata": {
        "id": "lwfwkhjiOIV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop(['Class'], axis=1)\n",
        "y = df['Class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "8PxHFCOYOH1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing Random Forest\n"
      ],
      "metadata": {
        "id": "54iCYB0xOqt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(n_estimators= 100)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "print(\"Random Forest Predictions:\", rf_pred)"
      ],
      "metadata": {
        "id": "22nT2w94OQHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_score = rf_model.score(X_test, y_test) * 100\n",
        "\n",
        "print(\"Random Forest Score: \", random_forest_score)"
      ],
      "metadata": {
        "id": "K12m8z5CP-Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check the performance metrics"
      ],
      "metadata": {
        "id": "51KliJ8eQNmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(\"Random Forest Performance Metrics:\\n\", classification_report(y_test, rf_pred))"
      ],
      "metadata": {
        "id": "XixaSgsEQI_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC Curve"
      ],
      "metadata": {
        "id": "H7229DuKTWMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
        "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
        "rf_auc = auc(rf_fpr, rf_tpr)"
      ],
      "metadata": {
        "id": "924coqewTVzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(rf_fpr, rf_tpr, label=f\"Random Forest (AUC = {rf_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hHh5lBsRTavd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Precision Recall Curve"
      ],
      "metadata": {
        "id": "Lth4-77jThgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "rf_precision, rf_recall, _ = precision_recall_curve(y_test, rf_probs)\n",
        "plt.plot(rf_recall, rf_precision, label=\"Random Forest\")\n",
        "\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OcaFW-AVTeUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A0Cr_ZmTTmtW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}